#!/usr/bin/env python3
"""
Fetch comprehensive historical stock data for global tickers.
Defaults to using 'all_tickers.txt' (generated by discover_tickers.py).
Resolutions: Daily (1d), Weekly (1wk), Monthly (1mo).
"""

import argparse
import sys
import os
from datetime import datetime, timezone, timedelta
from typing import List, Optional

import pandas as pd
import yfinance as yf
from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Date, Float, UniqueConstraint
from sqlalchemy.dialects.sqlite import insert
from tqdm import tqdm

# Database configuration
DATABASE_FILE = "stockdb.sqlite"
DATABASE_URL = f"sqlite:///{DATABASE_FILE}"

# Create database engine
engine = create_engine(DATABASE_URL)
metadata = MetaData()

# Define the table schema
stock_eod = Table(
    'stock_eod', metadata,
    Column('id', Integer, primary_key=True, autoincrement=True),
    Column('symbol', String, nullable=False),
    Column('interval', String, nullable=False),
    Column('date', Date, nullable=False),
    Column('open', Float),
    Column('high', Float),
    Column('low', Float),
    Column('close', Float),
    Column('volume', Integer),
    Column('adjusted_close', Float),
    UniqueConstraint('symbol', 'interval', 'date', name='idx_symbol_interval_date')
)

# Standard historical intervals
TIME_INTERVALS = ['1d', '1wk', '1mo']

def ensure_table():
    """Create the stock_eod table if it doesn't exist."""
    metadata.create_all(engine)
    print(f"âœ… Database initialized: {DATABASE_FILE}")


def fetch_ticker_data(symbol: str, interval: str = '1d', start: str = '1900-01-01', end: Optional[str] = None) -> int:
    """
    Fetch historical stock data for a specific interval and upsert into the database.
    """
    try:
        ticker = yf.Ticker(symbol)
        end = end or datetime.now(timezone.utc).strftime("%Y-%m-%d")
        
        # Fetch data
        df = ticker.history(start=start, end=end, interval=interval, actions=False)
        
        if df is None or df.empty:
            return 0
        
        # Clean and format data
        df = df.reset_index()
        df.columns = [c.lower() for c in df.columns]
        
        rename_map = {
            'date': 'date',
            'open': 'open',
            'high': 'high',
            'low': 'low',
            'close': 'close',
            'volume': 'volume',
            'adj close': 'adjusted_close'
        }
        df.rename(columns=rename_map, inplace=True)
        
        # Ensure date is a python date object
        if 'date' not in df.columns:
            return 0
            
        df['date'] = pd.to_datetime(df['date']).dt.date
        
        # Prepare list of dictionaries for insertion
        rows = []
        for _, r in df.iterrows():
            row = {
                'symbol': symbol,
                'interval': interval,
                'date': r['date'],
                'open': float(r['open']) if pd.notna(r.get('open')) else None,
                'high': float(r['high']) if pd.notna(r.get('high')) else None,
                'low': float(r['low']) if pd.notna(r.get('low')) else None,
                'close': float(r['close']) if pd.notna(r.get('close')) else None,
                'volume': int(r['volume']) if pd.notna(r.get('volume')) else None,
                'adjusted_close': float(r.get('adjusted_close')) if pd.notna(r.get('adjusted_close')) else None
            }
            # If adjusted_close is missing, use close (common in yfinance if no split/div)
            if row['adjusted_close'] is None and row['close'] is not None:
                row['adjusted_close'] = row['close']
                
            rows.append(row)
        
        if not rows:
            return 0

        # Perform Upsert
        stmt = insert(stock_eod).values(rows)
        do_update_stmt = stmt.on_conflict_do_update(
            index_elements=['symbol', 'interval', 'date'],
            set_={
                'open': stmt.excluded.open,
                'high': stmt.excluded.high,
                'low': stmt.excluded.low,
                'close': stmt.excluded.close,
                'volume': stmt.excluded.volume,
                'adjusted_close': stmt.excluded.adjusted_close
            }
        )

        with engine.begin() as conn:
            conn.execute(do_update_stmt)
            return len(rows)

    except Exception as e:
        return 0


def main():
    parser = argparse.ArgumentParser(description='Fetch stock data for all tickers.')
    parser.add_argument('--file', type=str, default='all_tickers.txt',
                       help='Path to ticker list file (default: all_tickers.txt)')
    parser.add_argument('--batch-size', type=int, default=None,
                       help='Limit number of tickers (for testing)')
    parser.add_argument('--workers', type=int, default=1, 
                       help='(Optional) Number of threads - currently single threaded for safety')
    parser.add_argument('--days', type=int, default=None,
                       help='Fetch only the last N days (useful for daily updates)')
    
    args = parser.parse_args()
    
    # Load tickers
    if not os.path.exists(args.file):
        print(f"âŒ Error: Ticker file '{args.file}' not found.")
        print("   Run 'python discover_tickers.py' first.")
        sys.exit(1)
        
    with open(args.file, 'r') as f:
        tickers = [line.strip() for line in f if line.strip()]
        
    # Sort and remove duplicates
    tickers = sorted(list(set(tickers)))
    
    # Calculate start date
    start_date = '1900-01-01'
    if args.days:
        start_dt = datetime.now(timezone.utc) - timedelta(days=args.days)
        start_date = start_dt.strftime('%Y-%m-%d')
    
    print(f"\nğŸš€ Starting Data Fetch")
    print(f"   Source: {args.file}")
    print(f"   Tickers: {len(tickers)}")
    print(f"   Intervals: {', '.join(TIME_INTERVALS)}")
    print(f"   Start Date: {start_date}")
    
    if args.batch_size:
        tickers = tickers[:args.batch_size]
        print(f"   âš ï¸  Limited to first {len(tickers)} tickers")

    ensure_table()
    
    successful = 0
    failed = 0
    total_rows = 0
    
    # Progress bar
    pbar = tqdm(tickers, unit="ticker")
    for ticker in pbar:
        pbar.set_description(f"{ticker}")
        
        ticker_rows = 0
        ticker_success = False
        
        for interval in TIME_INTERVALS:
            rows = fetch_ticker_data(ticker, interval=interval, start=start_date)
            ticker_rows += rows
            if rows > 0:
                ticker_success = True
        
        if ticker_success:
            successful += 1
            total_rows += ticker_rows
        else:
            failed += 1
            
        # Update postfix stats every 10 tickers to avoid flickering
        if (successful + failed) % 10 == 0:
            pbar.set_postfix({"Rows": f"{total_rows:,}", "OK": successful, "Fail": failed})

    print(f"\n{'='*60}")
    print(f"ğŸ“Š SUMMARY")
    print(f"   âœ… Successful: {successful}")
    print(f"   âŒ Failed/No Data: {failed}")
    print(f"   ğŸ“ˆ Total Rows: {total_rows:,}")
    print(f"   ğŸ’¾ Database: {DATABASE_FILE}")
    print(f"{'='*60}\n")

if __name__ == "__main__":
    main()
